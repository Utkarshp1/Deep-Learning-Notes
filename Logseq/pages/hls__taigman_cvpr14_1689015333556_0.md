file:: [taigman_cvpr14_1689015333556_0.pdf](../assets/taigman_cvpr14_1689015333556_0.pdf)
file-path:: ../assets/taigman_cvpr14_1689015333556_0.pdf

- In modern face recognition, the conventional pipeline consists of four stages: detect ⇒ align ⇒ represent ⇒ classify. 
  ls-type:: annotation
  hl-page:: 1
  hl-color:: yellow
  id:: 64ac5496-e2e6-486b-9267-0f31a186025e
- Max-pooling layers make the output of convolution networks more robust to local translations. When applied to aligned facial images, they make the network more robust to small registration errors. However, several levels of pooling would cause the network to lose information about the precise position of detailed facial structure and micro-textures. Hence, we apply max-pooling only to the first convolutional layer. 
  ls-type:: annotation
  hl-page:: 3
  hl-color:: yellow
  id:: 64ac56ad-b6fe-4e80-ab55-a1ed26003bf2
- The subsequent layers (L4, L5 and L6) are instead locally connected [13, 16], like a convolutional layer they apply a filter bank, but every location in the feature map learns a different set of filters. Since different regions of an aligned image have different local statistics, the spatial stationarity assumption of convolution cannot hold. For example, areas between the eyes and the eyebrows exhibit very different appearance and have much higher discrimination ability compared to areas between the nose and the mouth. In other words, we customize the architecture of the DNN by leveraging the fact that our input images are aligned.
  ls-type:: annotation
  hl-page:: 4
  hl-color:: yellow
  id:: 64ac57bf-68b0-4c54-bb63-fd6fcd7c3732
- As a final stage we normalize the features to be between zero and one in order to reduce the sensitivity to illumination changes: Each component of the feature vector is divided by its largest value across the training set. This is then followed by L2-normalization:
  ls-type:: annotation
  hl-page:: 4
  hl-color:: yellow
  id:: 64ac5967-3016-4568-ba1f-c1dab626aca5
- Since we employ ReLU activations, our system is not invariant to re-scaling of the image intensities. Without bi-
  ls-type:: annotation
  hl-page:: 4
  hl-color:: yellow
  id:: 64ac5c59-11ec-499a-9a46-49b6bf9eae21
- ases in the DNN, perfect equivariance would have been achieved.
  ls-type:: annotation
  hl-page:: 5
  hl-color:: yellow
  id:: 64ac5c66-6151-4d68-b5b7-1a9866ed810c
- One interesting property of the features produced by this network is that they are very sparse. On average, 75% of the feature components in the topmost layers are exactly zero. This is mainly due to the use of the ReLU [10] activation function: max(0, x). This soft-thresholding non-linearity is applied after every convolution, locally connected and fully connected layer (except the last one), making the whole cascade produce highly non-linear and sparse features. Sparsity is also encouraged by the use of a regularization method called dropout [19] which sets random feature components to 0 during training.
  ls-type:: annotation
  hl-page:: 4
  hl-color:: yellow
  id:: 64ac5e63-70ba-4bf7-abb2-d38a4bada45d
- This is accomplished by: a) taking the absolute difference between the features, followed by b) a top fully connected layer that maps into a single logistic unit (same/not same). The network has roughly the same number of parameters as the original one, since much of it is shared between the two replicas, but requires twice the computation. Notice that in order to prevent overfitting on the face verification task, we enable training for only the two topmost layers.
  ls-type:: annotation
  hl-page:: 5
  hl-color:: yellow
  id:: 64ac6064-4c82-46e9-afd0-e94a2304f5a5
- We combine those distances using a non-linear SVM (with C=1) with a simple sum of power CPD-kernels: KCombined := Ksingle + Kgradient + Kalign2d, where K(x, y) := −||x − y||2, and following the restricted protocol, achieve an accuracy 97.15%.
  ls-type:: annotation
  hl-page:: 7
  hl-color:: yellow
  id:: 64ac62bb-5430-4026-bbaa-af2ba3e0f52a